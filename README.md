<h1 align="center">Multimodal Biometric Identification System</h1>

<div align="center">
  <img src="https://img.shields.io/badge/python-3.10%2B-blue?style=for-the-badge" alt="Python Version">
  <img src="https://img.shields.io/badge/OpenCV-4.x-green?style=for-the-badge" alt="OpenCV">
  <img src="https://img.shields.io/badge/Numpy-SciPy-yellow?style=for-the-badge" alt="Libraries">
  <img src="https://img.shields.io/badge/Status-Under%20Development-orange?style=for-the-badge" alt="Status">
</div>

---

# Introduzione

Questo progetto implementa una **pipeline modulare e completamente automatizzata per lâ€™analisi, il preprocessing e il riconoscimento di impronte digitali ad alta risoluzione**.  
Lâ€™intero framework Ã¨ stato progettato per supportare sperimentazioni riproducibili e scalabili nel campo della biometria, integrando:

- tecniche avanzate di **image enhancement**,  
- estrazione accurata delle **minuzie**,  
- matching basato su invarianti geometriche,  
- gestione multi-dataset con parsing intelligente dei filename,  
- strumenti di valutazione (FAR, FRR, ROC) a livello sperimentale.

### Obiettivi principali del framework

- **Robustezza**: resistenza a variazioni di pressione, rotazione, contrasto, rumore e parziale sovrapposizione delle ridge.  
- **ModularitÃ **: ogni fase della pipeline (preprocessing â†’ estrazione â†’ matching â†’ valutazione) puÃ² essere sostituita o estesa.  
- **RiproducibilitÃ **: ogni trasformazione Ã¨ tracciata e configurabile.  
- **Multi-dataset**: supporto integrato a dataset con formati eterogenei e convenzioni diverse.

### Tecnologie utilizzate

- **Python 3.x**  
- Librerie scientifiche: `NumPy`, `SciPy`, `OpenCV`, `scikit-image`  
- Machine learning e KD-Tree: `scikit-learn`  
- Analisi e catalogazione dataset: `pandas`, `tqdm`  
- Logging, benchmarking e strumenti diagnostici integrati.

---

# Dataset utilizzati

La pipeline supporta e normalizza **qualunque dataset di impronte digitali con formato leggibile**, tramite un sistema di riconoscimento dei filename basato su espressioni regolari.  
In questo progetto sono stati impiegati due dataset principali:

---

## ðŸ“Œ PolyU High Resolution Fingerprint Database II (PolyU HRF DBII)

Questo dataset rappresenta un riferimento consolidato nella ricerca sulle impronte digitali ad alta risoluzione.

### Caratteristiche principali

| ProprietÃ  | Valore |
|------------|--------|
| Origine | Hong Kong Polytechnic University |
| Nome | High Resolution Fingerprint Database II (DBII) |
| Soggetti | 148 |
| Immagini per soggetto | 10 |
| Totale immagini | 1480 |
| Risoluzione | 1200 dpi (â‰ˆ 21 Âµm/pixel) |
| Formato | JPG â€“ 8-bit grayscale |
| Dimensioni | ~240Ã—320 px |

> [!NOTE]  
> Ogni soggetto dispone di 10 acquisizioni indipendenti, con variazioni di rotazione, pressione, area acquisita e condizioni di contatto.  
> Questo lo rende ideale per valutare la stabilitÃ  delle minuzie e lâ€™affidabilitÃ  del matching.

---

## ðŸ“Œ NIST Fingerprint

Oltre al PolyU HRF, il progetto integra anche delle impronte **NIST**, caratterizzate da elevate difficoltÃ  strutturali:

- impronte estremamente degradate,  
- artefatti e zone sature,  
- ridotto contrasto,  
- geometrie incomplete o danneggiate,
- acquisizione grossolana non ottima.

### Caratteristiche riconosciute

| ProprietÃ  | Valore |
|-----------|--------|
| Nome pattern | `Fxxxx_nn.bmp` |
| Esempio | `F0001_01.bmp` |
| Parsing automatico | SÃ¬ (subject, finger, session=1) |
| ComplessitÃ  | Molto alta |
| Formato | BMP, 8-bit grayscale |

> [!TIP]  
> Le impronte NIST sono utilizzate principalmente per **stress-test** della pipeline, poichÃ© contengono casi estremi che mettono in difficoltÃ  i metodi convenzionali.

---

# Sistema di Catalogazione Dataset

Per uniformare i dataset PolyU e NIST, la pipeline utilizza il modulo:
```bash
src/catalog/catalog.py
```
Questo componente:
1. **scansiona automaticamente tutti i cluster** (cartelle `cluster_*`);
2. **riconosce automaticamente il formato del filename** tramite tre regex:
   - `3_1_1.jpg` â†’ formato standard  
   - `F0003_10.bmp` â†’ formato NIST  
   - `S1387_02.bmp` â†’ formato "S-pattern"  
3. **estrae i metadati**:  
   - `subject_id`  
   - `finger_id`  
   - `session_id`  
   - dimensioni dell'immagine  
   - cluster di appartenenza  
4. **genera un catalogo CSV** ordinato e pronto per tutte le successive fasi della pipeline.

>[!IMPORTANT]
>Lâ€™unificazione dei dataset tramite questa catalogazione Ã¨ fondamentale per permettere un matching affidabile e un calcolo coerente delle metriche (FRR / FAR / ROC).
---

## Estrazione e Clustering delle Feature

Prima di passare all'elaboraizione delle immagini, ogni impronta viene rappresentata tramite un **embedding vettoriale** ottenuto con modelli di **Self-Supervised Learning (SSL)**.  
Questi embeddings catturano le caratteristiche distintive delle ridge e permettono un confronto affidabile tra campioni.

### Aggregazione degli embeddings

Per ridurre la variabilitÃ  intra-soggetto dovuta a pressione, orientamento o rumore, gli embeddings degli stessi soggetti vengono aggregati (ad esempio tramite media), generando una **rappresentazione unica per ciascun soggetto**.

### Clustering Globale

Lâ€™obiettivo del clustering Ã¨ raggruppare immagini simili in base alle loro caratteristiche biometriche, senza fare uso degli ID reali dei soggetti. Questo approccio consente di:

- Valutare la capacitÃ  degli embeddings di distinguere soggetti diversi  
- Identificare pattern comuni tra impronte simili  
- Misurare la qualitÃ  della rappresentazione generata dal modello SSL

**Algoritmi applicati:**

1. **KMeans** â€“ Raggruppa i dati in cluster ottimizzando la coesione interna, lavorando su embeddings normalizzati per misurare la **cosine similarity**.  
2. **Agglomerative Clustering** â€“ Algoritmo gerarchico che unisce progressivamente i campioni piÃ¹ simili, utile per evidenziare eventuali sottogruppi.

### Riduzione dimensionale e visualizzazione

PoichÃ© gli embeddings sono ad alta dimensione, viene applicata una **riduzione dimensionale** (PCA o UMAP) prima della visualizzazione. Questo consente di:

- Osservare la distribuzione dei campioni nello spazio 2D o 3D  
- Valutare visivamente la separazione dei cluster  
- Individuare eventuali outlier o campioni ambigui

### Valutazione dei cluster

La qualitÃ  dei cluster viene quantificata attraverso metriche consolidate:

- **Silhouette Score** â€“ Misura coesione interna vs separazione  
- **Davies-Bouldin Index** â€“ Valuta quanto i cluster sono distinti e compatte le loro strutture  
- **Calinski-Harabasz Index** â€“ Analizza la dispersione tra e allâ€™interno dei cluster

> [!NOTE]  
> Questa sezione fornisce la logica e il razionale del clustering, senza entrare nei dettagli implementativi. Prepara il lettore a comprendere la pipeline pratica di esecuzione.

---

## Pipeline di Elaborazione e Matching

La pipeline Ã¨ articolata in fasi strutturate per garantire **precisione e robustezza** nel riconoscimento delle impronte digitali.

### Preprocessing

Le immagini vengono preparate tramite operazioni di preprocessing:

- Ridimensionamento e normalizzazione
- Rimozione del rumore tramite filtri e smoothing
- Eventuale binarizzazione preliminare per evidenziare dettagli delle ridge

### Segmentazione con Deep Learning

Il modello **UNet o SSL** segmenta le ridge principali, isolando le regioni di interesse:

- Estrazione delle strutture fondamentali  
- Miglioramento del rapporto segnale/rumore  
- Facilitazione dellâ€™estrazione delle feature

### Estrazione delle feature e minutiae

Dalla segmentazione si estraggono:

- **Minutiae**: biforcazioni, terminazioni e punti caratteristici  
- **Embeddings vettoriali**: rappresentazioni numeriche dense dellâ€™impronta, utili per il confronto

### Post-Processing

- Aggregazione intra-soggetto delle feature  
- Selezione delle minutiae migliori in base a criteri di qualitÃ  e distribuzione  
- Normalizzazione degli embeddings per uniformare la scala

### Matching e valutazione delle prestazioni

Il sistema utilizza un modello di matching basato su **RANSAC** e **trasformazioni rigide**, progettato per confrontare strutture di minutiae in modo robusto contro rotazioni, traslazioni e distorsioni locali.

#### Matching tra campioni

Il confronto tra due impronte avviene in tre fasi:

1. **Selezione preliminare delle corrispondenze**
   - ciascuna minutia viene confrontata con le vicine (KDTree)
   - vengono applicati vincoli su:
     - distanza locale
     - differenza di orientazione
     - tipo della minutia (ending/bifurcation)

2. **Stima della trasformazione (RANSAC)**
   - si cerca la rotazione + traslazione che massimizza gli *inliers*
   - le minutiae vengono allineate nel sistema di riferimento comune

3. **Valutazione delle corrispondenze**
   - ogni coppia minutiaâ€“minutia allineata riceve un **peso**
     basato su:
     - coerenza geometrica
     - differenza angolare
     - tipo della minutia
     - qualitÃ  locale
   - lo **score finale** Ã¨ normalizzato in $([0, 1])$:
     - **1 â†’ impronte altamente corrispondenti**
     - **0 â†’ quasi certamente impostore**

#### Threshold e metriche

Il sistema calcola le metriche biometriche standard:

- **FRR(t)** â€“ False Reject Rate: genuine con score < t  
- **FAR(t)** â€“ False Accept Rate: impostor con score â‰¥ t  

Effetto del threshold:

- Threshold basso â†’ FRR piÃ¹ alto (sistema piÃ¹ severo)  
- Threshold alto â†’ FAR piÃ¹ alto (sistema piÃ¹ permissivo)  

> [!NOTE]  
> Questo approccio combina robustezza geometrica e pesatura delle minutiae,
> offrendo un matching stabile anche in presenza di rumore, rotazioni e pressioni non uniformi.

## Struttura PipeLine
  
Ogni fase della pipeline genera un output intermedio, utilizzato come input per la successiva.

```bash
input â†’ Normalizzazione â†’ Segmentazione â†’ Binarizzazione â†’ Thinning â†’ Orientamento â†’ Estrazione minutiae â†’ Matching
```

## Struttura della repository

```bash
â”œâ”€â”€ ðŸ“ classifier
â”‚   â”‚
â”‚   â”œâ”€â”€ ðŸ“ dataset2
â”‚   â”‚   â”œâ”€â”€ ðŸ dataset.py
â”‚   â”‚   â””â”€â”€ ðŸ preprocessing.py
â”‚   â”‚
â”‚   â”œâ”€â”€ ðŸ“ models
â”‚   â”‚   â”œâ”€â”€ ðŸ backbone.py
â”‚   â”‚   â”œâ”€â”€ ðŸ projection_head.py
â”‚   â”‚   â””â”€â”€ ðŸ ssl_model.py
â”‚   â”‚
â”‚   â”œâ”€â”€ ðŸ“ utils
â”‚   â”‚   â”œâ”€â”€ ðŸ cluster_embeddings.py
â”‚   â”‚   â”œâ”€â”€ ðŸ extract_embeddings.py
â”‚   â”‚   â”œâ”€â”€ ðŸ loss.py
â”‚   â”‚   â”œâ”€â”€ ðŸ train_ssl.py
â”‚   â”‚   â””â”€â”€ ðŸ utils.py
â”‚   â”‚
â”‚   â”œâ”€â”€ ðŸ main_ssl_pipeline.py
â”‚   â”œâ”€â”€ ðŸ sorted.py
â”‚   â””â”€â”€ ðŸ verify.py
â”‚
â”œâ”€â”€ ðŸ“ config
â”‚   â”œâ”€â”€ ðŸ config_classifier.py
â”‚   â”œâ”€â”€ âš™ï¸ config_classifier.yml
â”‚   â”œâ”€â”€ ðŸ config_fingerprint.py
â”‚   â”œâ”€â”€ âš™ï¸ config_fingerprint.yml
â”‚   â”œâ”€â”€ âš™ï¸ config_matching.yml
â”‚   â”œâ”€â”€ âš™ï¸ config_path.yml
â”‚   â”œâ”€â”€ âš™ï¸ config_segmentation.yml
â”‚   â””â”€â”€ âš™ï¸ environment.yml
â”‚
â”œâ”€â”€ ðŸ“ src
â”‚   â”œâ”€â”€ ðŸ“ catalog
â”‚   â”‚   â”œâ”€â”€ ðŸ __init__.py
â”‚   â”‚   â””â”€â”€ ðŸ prepare_catalog.py
â”‚   â”‚
â”‚   â”œâ”€â”€ ðŸ“ features
â”‚   â”‚   â”œâ”€â”€ ðŸ __init__.py
â”‚   â”‚   â”œâ”€â”€ ðŸ extract_features.py
â”‚   â”‚   â””â”€â”€ ðŸ post_processing.py
â”‚   â”‚
â”‚   â”œâ”€â”€ ðŸ“ matching
â”‚   â”‚   â”œâ”€â”€ ðŸ FAR.py
â”‚   â”‚   â”œâ”€â”€ ðŸ FRR.py
â”‚   â”‚   â”œâ”€â”€ ðŸ ROC.py
â”‚   â”‚   â”œâ”€â”€ ðŸ __init__.py
â”‚   â”‚   â”œâ”€â”€ ðŸ match.py
â”‚   â”‚   â”œâ”€â”€ ðŸ match_features.py
â”‚   â”‚   â””â”€â”€ ðŸ utils.py
â”‚   â””â”€â”€ ðŸ“ preprocessing
â”‚       â”‚
â”‚       â”œâ”€â”€ ðŸ“ segmentation
â”‚       â”‚   â”œâ”€â”€ ðŸ __init__.py
â”‚       â”‚   â”œâ”€â”€ ðŸ dataset.py
â”‚       â”‚   â”œâ”€â”€ ðŸ inference.py
â”‚       â”‚   â”œâ”€â”€ ðŸ model.py
â”‚       â”‚   â””â”€â”€ ðŸ train.py
â”‚       â”‚
â”‚       â”œâ”€â”€ ðŸ __init__.py
â”‚       â”œâ”€â”€ ðŸ fingerprint_preprocess.py
â”‚       â”œâ”€â”€ ðŸ orientation.py
â”‚       â””â”€â”€ ðŸ run_preprocessing.py
â”‚
â”œâ”€â”€ âš™ï¸ .gitignore
â”œâ”€â”€ ðŸ“ README.md
â”‚
â”œâ”€â”€ ðŸ“„ prepare.bat
â””â”€â”€ ðŸ“„ prepare.sh
```

---

> [!CAUTION]
> Note:
Il progetto Ã¨ ancora in fase di sviluppo.

--- 

<!--â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€-->
<!--                   AUTORE                     -->
<!--â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€-->

<h2 align="center">âœ¨ Autore</h2>

<p align="center">
  <strong>Giovanni Giuseppe Iacuzzo</strong><br>
  <em>Studente di Ingegneria Dell'IA e della CyberSecurity Â· UniversitÃ  degli Studi Kore di Enna</em>
</p>

<p align="center">
  <a href="https://github.com/giovanniIacuzzo" target="_blank">
    <img src="https://img.shields.io/badge/GitHub-%40giovanniIacuzzo-181717?style=for-the-badge&logo=github" alt="GitHub"/>
  </a>
  <a href="mailto:giovanni.iacuzzo@unikorestudent.com">
    <img src="https://img.shields.io/badge/Email-Contattami-blue?style=for-the-badge&logo=gmail" alt="Email"/>
  </a>
</p>